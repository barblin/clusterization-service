{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/githubrepo/AdaWaveClustering/AdaWave/syntheticData/waveData_5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-2a0b75637e77>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mfpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfpath_base\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'waveData_5.csv'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mcol_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'feat-1'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'feat-2'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'labels'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcol_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'feat-1'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'feat-2'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m#col_names.remove('index')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    684\u001B[0m     )\n\u001B[0;32m    685\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 686\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    451\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 452\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    453\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    454\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    945\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 946\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    947\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    948\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1176\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"c\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1177\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"c\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1178\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1179\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1180\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"python\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\johan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   2006\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"usecols\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2007\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2008\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2009\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2010\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/path/to/githubrepo/AdaWaveClustering/AdaWave/syntheticData/waveData_5.csv'"
     ]
    }
   ],
   "source": [
    "# path to github repo where \n",
    "fpath_base = '/path/to/githubrepo/AdaWaveClustering/AdaWave/syntheticData/'\n",
    "fpath = fpath_base + 'waveData_5.csv'\n",
    "col_names = ['feat-1', 'feat-2', 'labels']\n",
    "data = pd.read_csv(fpath, names=col_names)\n",
    "columns = ['feat-1', 'feat-2']\n",
    "#col_names.remove('index')\n",
    "#data = data[col_names]\n",
    "data = data.astype({'labels': 'int32'})\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data in a 2D projection to get a feeling of the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = 1002\n",
    "plt.figure(figsize=(8,6))\n",
    "col_map = {0: 'tab:grey', 1: 'tab:orange', 2: 'tab:red', 3: 'tab:blue', 4:'tab:purple', 5:'tab:green', 6:'tab:cyan'}\n",
    "plt.scatter(data['feat-1'], data['feat-2'], alpha=0.8, s=1, color=[col_map[sample] for sample in data.labels])\n",
    "#plt.scatter(df['f1'], df['f2'], c=df['label'])\n",
    "#plt.scatter(data[pt,0], data[pt,1], marker='x', s=100, lw=4, color='r')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('feature 1', size=15, labelpad=10)\n",
    "plt.ylabel('feature 2', size=15, labelpad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get neighborhood of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Get nearest neighbor indices\n",
    "k_nn = 200\n",
    "df_nbh = data[columns].copy()\n",
    "SCALE_DATA = False\n",
    "if SCALE_DATA:\n",
    "    c_x = 1\n",
    "    c_y = 1\n",
    "    df_nbh /= df_nbh.std()\n",
    "    df_nbh[cols_position] *= c_pos\n",
    "    df_nbh[cols_propermtn] *= c_vel\n",
    "\n",
    "nbh_model = NearestNeighbors(algorithm='ball_tree', metric='minkowski',\n",
    "                             metric_params=None, leaf_size=30, p=2, n_jobs=-1)\n",
    "nbh_model.fit(df_nbh)\n",
    "nbh_distances, nbh_indices = nbh_model.kneighbors(df_nbh, k_nn, return_distance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose point to visualize\n",
    "cluster_idx = 1  # cluster_idx = [0,1,2,3,4,5]\n",
    "idx = 10\n",
    "data_idx = np.arange(data.shape[0])[data.labels==cluster_idx][idx]\n",
    "nbh_idx = nbh_indices[data_idx]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "col_map = {0: 'tab:grey', 1: 'tab:orange', 2: 'tab:red', 3: 'tab:blue', 4:'tab:purple', 5:'tab:green', 6:'tab:cyan'}\n",
    "\n",
    "plt.scatter(data['feat-1'], data['feat-2'], s=1, c='tab:grey', alpha=0.5) # , color=[col_map[sample] for sample in data.labels])\n",
    "plt.scatter(data['feat-1'].iloc[nbh_idx], data['feat-2'].iloc[nbh_idx], c='tab:orange', alpha=0.9, s=2)\n",
    "plt.scatter(data.iloc[data_idx]['feat-1'], data.iloc[data_idx]['feat-2'], marker='x', s=100, lw=2, color='k')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('feature 1', size=15, labelpad=10)\n",
    "plt.ylabel('feature 2', size=15, labelpad=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/sebastian/Documents/PhD/pyprojects/neighborhood')\n",
    "from filter_neighborhood import local_reachability_density, lrd_filter, gauss_sample\n",
    "\n",
    "lrd_data = local_reachability_density(df_nbh, k=4, n=15)\n",
    "_, nbh_indices_lrd = lrd_filter(nbh_distance=nbh_distances, nbh_indices=nbh_indices, lrd_data=lrd_data, threshold=0.6, keep_min=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, nbh_indices_gauss = gauss_sample(nbh_distance=nbh_distances, nbh_indices=nbh_indices, alpha=1, power=1, draw_n_samples=300, weight_dist=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate wasserstein distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the wasserstein distance only between the nearest k_wasser neighbors\n",
    "k_wasser = 200\n",
    "_, nbh_indices_wasser = nbh_model.kneighbors(df_nbh, k_wasser, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique pairs of neighbors\n",
    "calc_wasserstein_index_set = set()\n",
    "for center_idx in range(nbh_indices_wasser.shape[0]):\n",
    "    for idx in nbh_indices_wasser[center_idx][1:]:\n",
    "        calc_wasserstein_index_set.add(frozenset({center_idx, idx}))\n",
    "len(calc_wasserstein_index_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating wasserstein distance â†’ this might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = nbh_distances\n",
    "\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "wasserstein_dist = []\n",
    "for idx_set in calc_wasserstein_index_set:\n",
    "    idx_i, idx_j = idx_set\n",
    "    dist = wasserstein_distance(dist_list[idx_i], dist_list[idx_j])\n",
    "    wasserstein_dist.extend([dist, dist])\n",
    "    row_indices.extend([idx_i, idx_j])  # symmetrical matrix\n",
    "    col_indices.extend([idx_j, idx_i])  # --------||---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "nb_datapts = data.shape[0]\n",
    "dist_mtrx = csr_matrix((wasserstein_dist, (row_indices, col_indices)), shape=(nb_datapts, nb_datapts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN   # DBSCAN gives us \"wasserstein\" connected points\n",
    "db = DBSCAN(metric=\"precomputed\", eps=0.5, min_samples=50).fit(dist_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = db.labels_\n",
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels)\n",
    "#for l_i in unique_labels:\n",
    "    #break\n",
    "    #if len(labels[labels==l_i])<200 or len(labels[labels==l_i])>2500:\n",
    "    #    labels[labels==l_i] = -1\n",
    "np.unique(labels)\n",
    "\n",
    "REMOVE = False\n",
    "if REMOVE:\n",
    "    for li in [5,6,7]:\n",
    "        labels[labels==li] = -1\n",
    "\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "#col_map = {-1: 'tab:grey', 0: 'tab:orange', 1: 'tab:red', 2: 'tab:blue', 3:'tab:purple', 4:'tab:green', 5:'tab:cyan', 6:'k'}\n",
    "plt.scatter(data['feat-1'], data['feat-2'], alpha=0.8, s=3, c=labels, cmap='Set2')  #, c=[col_map[sample] for sample in labels])\n",
    "#plt.scatter(df['f1'], df['f2'], c=df['label'])\n",
    "#plt.scatter(data[pt,0], data[pt,1], marker='x', s=100, lw=4, color='r')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('feature 1', size=15, labelpad=10)\n",
    "plt.ylabel('feature 2', size=15, labelpad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "adjusted_mutual_info_score(data['labels'], labels)      # if you choose to merge the regions (set REMOVE=True 2 cells above) then you can improve the AMI to ~0.87 in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local density estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_reachability_density(data, k, n, **nn_kwargs):\n",
    "    \"\"\"\n",
    "    Reachability distance: maximum of the distance of two points and the k-distance of the second point\n",
    "    In practice we only need the reachability distance between the nearest neighbors, so therefore we first build a kd/ball tree and then calculate the\n",
    "    :param data: pandas DataFrame or numpy.ndarray\n",
    "    :param k: integer; distance to that neighbor is calculated (for k-distance)\n",
    "    :param n: Number of nearest neighbors used to calculate the LRD\n",
    "    :param nn_kwargs: Kwargs for NearestNeighbors class (sklearn)\n",
    "    :return: local reachability density for each point in the input data set 'data'\n",
    "    \"\"\"\n",
    "    if not isinstance(data, (pd.DataFrame, pd.Series, np.ndarray)):\n",
    "        raise TypeError('Variable \"df\" has to be of type pandas.DataFrame or pandas.Series')\n",
    "    nn = NearestNeighbors(n_neighbors=n+1, **nn_kwargs).fit(data)\n",
    "    ndist, _ = nn.kneighbors(data, n_neighbors=n+1, return_distance=True)\n",
    "    # the first k distances are now set to the k-distance\n",
    "    k_dist_idx = lambda i, k: i if (i>k) else k  # k-distance indices\n",
    "    idx = [k_dist_idx(i, k) for i in range(1, n+1)]\n",
    "    k_dist = ndist[:, idx]\n",
    "    # one over LRD\n",
    "    oo_lrd = np.sum(k_dist, axis=1)/n\n",
    "    return 1/oo_lrd\n",
    "\n",
    "lrd = local_reachability_density(data[columns], k=3, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}